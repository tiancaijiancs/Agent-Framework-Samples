{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f08567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.ai.agents.models import FilePurpose,VectorStore,FileSearchTool\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from agent_framework import AgentRunResponse,ChatAgent,HostedFileSearchTool,HostedVectorStoreContent\n",
    "from agent_framework.azure import AzureAIAgentClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a3bcf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d3ca050",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_vector_store(client: AzureAIAgentClient) -> tuple[str, VectorStore]:\n",
    "    \"\"\"Create a vector store with sample documents.\"\"\"\n",
    "    file_path = '../files/demo.md'\n",
    "    file = await client.project_client.agents.files.upload_and_poll(file_path=file_path, purpose=FilePurpose.AGENTS)\n",
    "    print(f\"Uploaded file, file ID: {file.id}\")\n",
    "\n",
    "\n",
    "    vector_store = await client.project_client.agents.vector_stores.create_and_poll(file_ids=[file.id], name=\"graph_knowledge_base\")\n",
    "\n",
    "    print(f\"Created vector store, ID: {vector_store.id}\")\n",
    "\n",
    "\n",
    "    return file.id, vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aef5316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file, file ID: assistant-CiUQ5xjyFBC7TJyJ331FCF\n",
      "Created vector store, ID: vs_BEbCqzLGHRRQsP0mMALlV5CV\n",
      "Agent created. You can now ask questions about the uploaded document.\n",
      "Assistant: GraphRAG is an AI-based content interpretation and search system that uses large language models to create a knowledge graph from a user-provided dataset. It connects information across large volumes of data to answer complex, thematic, or multi-document questions that are difficult to address through traditional keyword or vector search methods. The system is designed to support critical analysis and discovery, especially in contexts where information is noisy or spread across many sources. It emphasizes transparency, grounded responses, and resilience to injection attacks, although it relies on well-constructed indexing and human oversight for optimal performance【4:0†demo.md】.\n"
     ]
    }
   ],
   "source": [
    "async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential) as chat_client,\n",
    "    ):\n",
    "        file_id, vector_store = await create_vector_store(chat_client)\n",
    "\n",
    "        file_search = FileSearchTool(vector_store_ids=[vector_store.id])\n",
    "        \n",
    "        agent = chat_client.create_agent(\n",
    "            name=\"PythonRAGDemo\",\n",
    "            instructions=\"\"\"\n",
    "                You are a helpful assistant that helps people find information in a set of files.  If you can't find the answer in the files, just say you don't know. Do not make up an answer.\n",
    "                \"\"\",\n",
    "            tools=file_search.definitions,  # Tools available to the agent\n",
    "            tool_resources=file_search.resources,  # Resources for the tool\n",
    "        )\n",
    "                \n",
    "\n",
    "        print(\"Agent created. You can now ask questions about the uploaded document.\")\n",
    "\n",
    "        query = \"What is GraphRAG?\"\n",
    "        response = await AgentRunResponse.from_agent_response_generator(agent.run_stream(query, tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}}))\n",
    "        print(f\"Assistant: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03956e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
