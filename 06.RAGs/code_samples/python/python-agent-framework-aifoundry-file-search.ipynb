{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f08567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from agent_framework import AgentRunResponse,ChatAgent,HostedFileSearchTool,HostedVectorStoreContent\n",
    "from agent_framework.azure import AzureAIAgentClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a3bcf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d3ca050",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_vector_store(client: AzureAIAgentClient) -> tuple[str, HostedVectorStoreContent]:\n",
    "    \"\"\"Create a vector store with sample documents.\"\"\"\n",
    "    file_path = '../files/demo.md'\n",
    "    file = await client.project_client.agents.files.upload_and_poll(file_path=file_path, purpose=\"assistants\")\n",
    "    print(f\"Uploaded file, file ID: {file.id}\")\n",
    "\n",
    "\n",
    "    vector_store = await client.project_client.agents.vector_stores.create_and_poll(file_ids=[file.id], name=\"graph_knowledge_base\")\n",
    "\n",
    "    print(f\"Created vector store, ID: {vector_store.id}\")\n",
    "\n",
    "\n",
    "    return file.id, HostedVectorStoreContent(vector_store_id=vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aef5316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file, file ID: assistant-BFSfM7F8u6HMQu7MDAX5W6\n",
      "Created vector store, ID: vs_YmZfOqWkwxMBoQgTY8PWhIId\n",
      "Agent created. You can now ask questions about the uploaded document.\n",
      "GraphRAG is an AI-based content interpretation and search system that uses large language models (LLMs) to parse data into a knowledge graph. It allows users to ask questions about their private dataset and get answers that connect information across large volumes of documents. Unlike traditional keyword or vector-based search, GraphRAG can handle complex queries where the answers span many documents or are more thematic in nature.\n",
      "\n",
      "It is designed for critical information discovery and analysis, especially in contexts where data can be noisy, mixed with misinformation, or where questions are abstract. The system is intended for use with domain-specific corpora of text data and relies on users having domain expertise and a critical mindset to validate and interpret the AI-generated insights. \n",
      "\n",
      "GraphRAG has been evaluated on how accurately it represents datasets, how transparent and grounded its responses are, its resilience against various prompt and data injection attacks, and its rate of hallucinations.\n",
      "\n",
      "The system depends on well-constructed indexing of the data and works best with entity-rich, focused natural language text. While it includes robustness features, human oversight remains essential, especially to ensure trust and responsible use.\n",
      "\n",
      "In summary, GraphRAG helps answer complex, cross-document questions by building a knowledge graph from text and leveraging LLMs to provide grounded, insightful responses within a responsible analytic framework.\n",
      "\n",
      "These details are drawn from the GraphRAG Responsible AI FAQ document【4:0†demo.md】【4:1†demo.md】."
     ]
    }
   ],
   "source": [
    "async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential) as chat_client,\n",
    "    ):\n",
    "        file_id, vector_store = await create_vector_store(chat_client)\n",
    "\n",
    "        file_search = HostedFileSearchTool(inputs=vector_store)\n",
    "        \n",
    "        agent = chat_client.create_agent(\n",
    "            name=\"PythonRAGDemo\",\n",
    "            instructions=\"\"\"You are an AI assistant that helps people find information in a set of documents. Use the File Search tool to look up relevant information from the files when needed to answer user questions. If you don't know the answer, just say you don't know. Do not make up answers.\n",
    "                \"\"\",\n",
    "            tools=[file_search],  # Tools available to the agent\n",
    "            tool_choice = \"auto\",  # Let the agent decide when to use tools\n",
    "        )\n",
    "                \n",
    "\n",
    "        print(\"Agent created. You can now ask questions about the uploaded document.\")\n",
    "\n",
    "        query = \"What's GraphRAG?\"\n",
    "        async for chunk in agent.run_stream(query, tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.vector_store_id]}}):\n",
    "                \n",
    "            if chunk.text:\n",
    "                print(chunk.text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03956e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
