{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f08567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from agent_framework import AgentRunResponse,ChatAgent,HostedFileSearchTool,HostedVectorStoreContent\n",
    "from agent_framework.azure import AzureAIAgentClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a3bcf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d3ca050",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_vector_store(client: AzureAIAgentClient) -> tuple[str, HostedVectorStoreContent]:\n",
    "    \"\"\"Create a vector store with sample documents.\"\"\"\n",
    "    file_path = '../../files/demo.md'\n",
    "    file = await client.project_client.agents.files.upload_and_poll(file_path=file_path, purpose=\"assistants\")\n",
    "    print(f\"Uploaded file, file ID: {file.id}\")\n",
    "\n",
    "\n",
    "    vector_store = await client.project_client.agents.vector_stores.create_and_poll(file_ids=[file.id], name=\"graph_knowledge_base\")\n",
    "\n",
    "    print(f\"Created vector store, ID: {vector_store.id}\")\n",
    "\n",
    "\n",
    "    return file.id, HostedVectorStoreContent(vector_store_id=vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aef5316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file, file ID: assistant-1g8AiiPfubEWi4MxwtwvAe\n",
      "Created vector store, ID: vs_3zr01rWaOng2gD1LPllGNHCg\n",
      "Agent created. You can now ask questions about the uploaded document.\n",
      "GraphRAG is an AI-based content interpretation and search capability that uses large language models (LLMs) to parse data and create a knowledge graph. It can then answer user questions about a user-provided private dataset by connecting information across large volumes of data. This approach allows it to answer questions difficult or impossible to handle with traditional keyword or vector-based search, including thematic questions like identifying top themes in a dataset.\n",
      "\n",
      "GraphRAG is intended for critical information discovery and analysis where insights span many documents and the data may be noisy or contain misinformation. It's designed for users trained in responsible analytic approaches and critical reasoning, as human expert analysis is needed to verify and augment its outputs. It is deployed with a domain-specific text corpus and does not collect user data itself.\n",
      "\n",
      "The system has been evaluated on metrics such as accurate representation of data, transparency and groundedness of responses, resilience to prompt and data injection attacks, and low hallucination rates.\n",
      "\n",
      "Limitations include the need for well-constructed indexing examples, which can be costly, and the dependency on domain-specific concept identification for unique datasets. Operationally, it is best used by experienced domain users who critically analyze the system's outputs and verify provenance.\n",
      "\n",
      "In summary, GraphRAG combines LLMs and knowledge graph construction to enable advanced question answering and thematic analysis over complex, multi-document datasets in a responsible and expert-augmented manner【4:0†demo.md】."
     ]
    }
   ],
   "source": [
    "async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential) as chat_client,\n",
    "    ):\n",
    "        file_id, vector_store = await create_vector_store(chat_client)\n",
    "\n",
    "        file_search = HostedFileSearchTool(inputs=vector_store)\n",
    "        \n",
    "        agent = chat_client.create_agent(\n",
    "            name=\"PythonRAGDemo\",\n",
    "            instructions=\"\"\"You are an AI assistant that helps people find information in a set of documents. Use the File Search tool to look up relevant information from the files when needed to answer user questions. If you don't know the answer, just say you don't know. Do not make up answers.\n",
    "                \"\"\",\n",
    "            tools=[file_search],  # Tools available to the agent\n",
    "            tool_choice = \"auto\",  # Let the agent decide when to use tools\n",
    "        )\n",
    "                \n",
    "\n",
    "        print(\"Agent created. You can now ask questions about the uploaded document.\")\n",
    "\n",
    "        query = \"What's GraphRAG?\"\n",
    "        async for chunk in agent.run_stream(query, tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.vector_store_id]}}):\n",
    "                \n",
    "            if chunk.text:\n",
    "                print(chunk.text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03956e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
