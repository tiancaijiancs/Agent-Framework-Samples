{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a7e1e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install agent-framework-azure-ai -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f08567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from azure.ai.agents.models import FilePurpose,FileSearchTool\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "from agent_framework import ChatAgent,HostedFileSearchTool,HostedVectorStoreContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3bcf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d3ca050",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_vector_store(client: AIProjectClient) -> tuple[str, HostedVectorStoreContent]:\n",
    "    \"\"\"Create a vector store with sample documents.\"\"\"\n",
    "    file_path = '../../files/demo.md'\n",
    "    file = await client.agents.files.upload_and_poll(file_path=file_path, purpose=\"assistants\")\n",
    "    print(f\"Uploaded file, file ID: {file.id}\")\n",
    "\n",
    "\n",
    "    vector_store = await client.agents.vector_stores.create_and_poll(file_ids=[file.id], name=\"graph_knowledge_base\")\n",
    "\n",
    "    print(f\"Created vector store, ID: {vector_store.id}\")\n",
    "\n",
    "\n",
    "    return file.id, HostedVectorStoreContent(vector_store_id=vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aef5316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file, file ID: assistant-KTUZiULQcLW8KZw5dCUKBy\n",
      "Created vector store, ID: vs_n0I71Ytm0LgM4sfYPilDh2GH\n",
      "Agent created. You can now ask questions about the uploaded document.\n",
      "GraphRAG is an AI-based content interpretation and search capability. It uses large language models (LLMs) to parse data and create a knowledge graph, which it then uses to answer user questions about a user-provided private dataset.\n",
      "\n",
      "GraphRAG can connect information across large volumes of data and use those connections to answer complex questions that are difficult or impossible to answer with traditional keyword or vector-based searches. It can handle questions that span many documents and even thematic questions, such as identifying top themes in a dataset.\n",
      "\n",
      "The intended use of GraphRAG includes supporting critical information discovery and analysis, especially where information spans many documents, is noisy or mixed with misinformation, or where questions are abstract or thematic. It is designed for use by trained users applying responsible analytic and critical reasoning approaches and is typically deployed with domain-specific text corpora.\n",
      "\n",
      "GraphRAG has been evaluated for accuracy, transparency, resilience to prompt and data corpus injection attacks, and low hallucination rates, among other factors. The system depends on well-constructed indexing for effective operation and is best used when users have domain expertise to critically analyze and verify answers.\n",
      "\n",
      "For responsible use, human analysis and verification of the outputs are recommended, and users should ensure data privacy where applicable. GraphRAG works best on natural language text data that is entity-rich, focusing on people, places, organizations, or objects.\n",
      "\n",
      "This summary is based on detailed documentation about GraphRAG that covers its capabilities, evaluation, limitations, and operational factors for responsible use【4:0†demo.md】【4:1†demo.md】."
     ]
    }
   ],
   "source": [
    "async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AIProjectClient(endpoint=os.environ[\"AZURE_AI_PROJECT_ENDPOINT\"], credential=credential) as client,\n",
    "    ):\n",
    "\n",
    "        file_id, vector_store = await create_vector_store(client)\n",
    "        file_search = FileSearchTool(vector_store_ids=[vector_store.vector_store_id])\n",
    "        created_agent = await client.agents.create_agent(\n",
    "            model=os.environ[\"AZURE_AI_MODEL_DEPLOYMENT_NAME\"], \n",
    "            name=\"PythonRAGAgent\",\n",
    "            instructions=\"\"\"\n",
    "                    You are an AI assistant designed to answer user questions using only the information retrieved from the provided document(s).\n",
    "\n",
    "                    - If a user's question cannot be answered using the retrieved context, **you must clearly respond**: \n",
    "                    \"I'm sorry, but the uploaded document does not contain the necessary information to answer that question.\"\n",
    "                    - Do not answer from general knowledge or reasoning. Do not make assumptions or generate hypothetical explanations.\n",
    "                    - Do not provide definitions, tutorials, or commentary that is not explicitly grounded in the content of the uploaded file(s).\n",
    "                    - If a user asks a question like \"What is a Neural Network?\", and this is not discussed in the uploaded document, respond as instructed above.\n",
    "                    - For questions that do have relevant content in the document (e.g., Contoso's travel insurance coverage), respond accurately, and cite the document explicitly.\n",
    "\n",
    "                    You must behave as if you have no external knowledge beyond what is retrieved from the uploaded document.\n",
    "                    \"\"\",\n",
    "            tools = file_search.definitions,\n",
    "            tool_resources= file_search.resources\n",
    "        )\n",
    "        chat_client=AzureAIAgentClient(project_client=client, agent_id=created_agent.id)\n",
    "\n",
    "\n",
    "        async with ChatAgent(\n",
    "                # passing in the client is optional here, so if you take the agent_id from the portal\n",
    "                # you can use it directly without the two lines above.\n",
    "                chat_client=chat_client,\n",
    "            ) as agent:\n",
    "                    \n",
    "\n",
    "            print(\"Agent created. You can now ask questions about the uploaded document.\")\n",
    "\n",
    "            query = \"What's GraphRAG?\"\n",
    "\n",
    "            async for chunk in agent.run_stream(query, tools=HostedFileSearchTool(inputs=vector_store)):\n",
    "\n",
    "                if chunk.text:\n",
    "                    print(chunk.text, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
